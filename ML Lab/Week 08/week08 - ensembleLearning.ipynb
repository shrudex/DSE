{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b03f4c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: breast_cancer\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 10, 'max_depth': 5}\n",
      "Test size: 0.1, Accuracy: 0.93\n",
      "Test size: 0.2, Accuracy: 0.96\n",
      "Test size: 0.3, Accuracy: 0.95\n",
      "Test size: 0.4, Accuracy: 0.96\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 50, 'max_depth': 10}\n",
      "Test size: 0.1, Accuracy: 0.95\n",
      "Test size: 0.2, Accuracy: 0.96\n",
      "Test size: 0.3, Accuracy: 0.95\n",
      "Test size: 0.4, Accuracy: 0.97\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 100, 'max_depth': 15}\n",
      "Test size: 0.1, Accuracy: 0.95\n",
      "Test size: 0.2, Accuracy: 0.96\n",
      "Test size: 0.3, Accuracy: 0.95\n",
      "Test size: 0.4, Accuracy: 0.96\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Test size: 0.1, Accuracy: 0.95\n",
      "Test size: 0.2, Accuracy: 0.96\n",
      "Test size: 0.3, Accuracy: 0.95\n",
      "Test size: 0.4, Accuracy: 0.96\n",
      "\n",
      "\n",
      "Dataset: wine\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 10, 'max_depth': 5}\n",
      "Test size: 0.1, Accuracy: 1.00\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.98\n",
      "Test size: 0.4, Accuracy: 0.96\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 50, 'max_depth': 10}\n",
      "Test size: 0.1, Accuracy: 0.94\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.98\n",
      "Test size: 0.4, Accuracy: 0.99\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 100, 'max_depth': 15}\n",
      "Test size: 0.1, Accuracy: 0.94\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.98\n",
      "Test size: 0.4, Accuracy: 0.99\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Test size: 0.1, Accuracy: 0.94\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.98\n",
      "Test size: 0.4, Accuracy: 0.99\n",
      "\n",
      "\n",
      "Dataset: digits\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 10, 'max_depth': 5}\n",
      "Test size: 0.1, Accuracy: 0.88\n",
      "Test size: 0.2, Accuracy: 0.88\n",
      "Test size: 0.3, Accuracy: 0.89\n",
      "Test size: 0.4, Accuracy: 0.88\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 50, 'max_depth': 10}\n",
      "Test size: 0.1, Accuracy: 0.97\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.98\n",
      "Test size: 0.4, Accuracy: 0.97\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 100, 'max_depth': 15}\n",
      "Test size: 0.1, Accuracy: 0.95\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.97\n",
      "Test size: 0.4, Accuracy: 0.97\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Test size: 0.1, Accuracy: 0.96\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.97\n",
      "Test size: 0.4, Accuracy: 0.97\n",
      "\n",
      "\n",
      "Dataset: iris\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 10, 'max_depth': 5}\n",
      "Test size: 0.1, Accuracy: 1.00\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.96\n",
      "Test size: 0.4, Accuracy: 0.93\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 50, 'max_depth': 10}\n",
      "Test size: 0.1, Accuracy: 1.00\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.96\n",
      "Test size: 0.4, Accuracy: 0.93\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 100, 'max_depth': 15}\n",
      "Test size: 0.1, Accuracy: 1.00\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.96\n",
      "Test size: 0.4, Accuracy: 0.93\n",
      "\n",
      "Preprocessing: standard, Hyperparameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Test size: 0.1, Accuracy: 1.00\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.98\n",
      "Test size: 0.4, Accuracy: 0.93\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer, load_wine, load_digits, load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load the datasets\n",
    "datasets = {'breast_cancer': load_breast_cancer(), 'wine': load_wine(), 'digits': load_digits(), 'iris': load_iris()}\n",
    "\n",
    "# Define different sets of hyperparameters\n",
    "hyperparameters = [{'n_estimators': 10, 'max_depth': 5},\n",
    "                   {'n_estimators': 50, 'max_depth': 10},\n",
    "                   {'n_estimators': 100, 'max_depth': 15},\n",
    "                   {'n_estimators': 200, 'max_depth': 20}]\n",
    "\n",
    "# Define different test sizes\n",
    "test_sizes = [0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "# Define data preprocessing methods\n",
    "preprocessing_methods = {'standard': StandardScaler()}\n",
    "\n",
    "# Loop over the datasets\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    X, y = dataset.data, dataset.target\n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    \n",
    "    # Loop over the preprocessing methods\n",
    "    for preprocessing_name, preprocessing_method in preprocessing_methods.items():\n",
    "        # Apply the preprocessing method to the data\n",
    "        X = preprocessing_method.fit_transform(X)\n",
    "\n",
    "        # Loop over the hyperparameters\n",
    "        for params in hyperparameters:\n",
    "            print(f\"Preprocessing: {preprocessing_name}, Hyperparameters: {params}\")\n",
    "            \n",
    "            # Loop over the test sizes\n",
    "            for test_size in test_sizes:\n",
    "                # Split the data into training and testing sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=89)\n",
    "\n",
    "                # Initialize the classifier\n",
    "                clf = RandomForestClassifier(**params, random_state=42)\n",
    "\n",
    "                # Fit the classifier to the training data\n",
    "                clf.fit(X_train, y_train)\n",
    "\n",
    "                # Predict the labels of the test data\n",
    "                y_pred = clf.predict(X_test)\n",
    "\n",
    "                # Calculate the accuracy of the classifier on the test data\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                print(f\"Test size: {test_size}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "            print()\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa1f58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-1.7.5-py3-none-win_amd64.whl (70.9 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\codes\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\codes\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.5\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f5aa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: breast_cancer\n",
      "Preprocessing: standard, Classifier: AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codes\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 0.1, Accuracy: 0.93\n",
      "Test size: 0.2, Accuracy: 0.96\n",
      "Test size: 0.3, Accuracy: 0.96\n",
      "Test size: 0.4, Accuracy: 0.96\n",
      "\n",
      "Preprocessing: standard, Classifier: Gradient Boosting\n",
      "Test size: 0.1, Accuracy: 0.93\n",
      "Test size: 0.2, Accuracy: 0.95\n",
      "Test size: 0.3, Accuracy: 0.95\n",
      "Test size: 0.4, Accuracy: 0.94\n",
      "\n",
      "Preprocessing: standard, Classifier: XGBoost\n",
      "Test size: 0.1, Accuracy: 0.96\n",
      "Test size: 0.2, Accuracy: 0.96\n",
      "Test size: 0.3, Accuracy: 0.95\n",
      "Test size: 0.4, Accuracy: 0.96\n",
      "\n",
      "\n",
      "Dataset: wine\n",
      "Preprocessing: standard, Classifier: AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codes\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 0.1, Accuracy: 0.83\n",
      "Test size: 0.2, Accuracy: 0.86\n",
      "Test size: 0.3, Accuracy: 0.89\n",
      "Test size: 0.4, Accuracy: 0.90\n",
      "\n",
      "Preprocessing: standard, Classifier: Gradient Boosting\n",
      "Test size: 0.1, Accuracy: 0.94\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.98\n",
      "Test size: 0.4, Accuracy: 0.94\n",
      "\n",
      "Preprocessing: standard, Classifier: XGBoost\n",
      "Test size: 0.1, Accuracy: 0.89\n",
      "Test size: 0.2, Accuracy: 0.94\n",
      "Test size: 0.3, Accuracy: 0.98\n",
      "Test size: 0.4, Accuracy: 0.99\n",
      "\n",
      "\n",
      "Dataset: digits\n",
      "Preprocessing: standard, Classifier: AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codes\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 0.1, Accuracy: 0.25\n",
      "Test size: 0.2, Accuracy: 0.25\n",
      "Test size: 0.3, Accuracy: 0.25\n",
      "Test size: 0.4, Accuracy: 0.25\n",
      "\n",
      "Preprocessing: standard, Classifier: Gradient Boosting\n",
      "Test size: 0.1, Accuracy: 0.96\n",
      "Test size: 0.2, Accuracy: 0.96\n",
      "Test size: 0.3, Accuracy: 0.96\n",
      "Test size: 0.4, Accuracy: 0.96\n",
      "\n",
      "Preprocessing: standard, Classifier: XGBoost\n",
      "Test size: 0.1, Accuracy: 0.95\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.96\n",
      "Test size: 0.4, Accuracy: 0.96\n",
      "\n",
      "\n",
      "Dataset: iris\n",
      "Preprocessing: standard, Classifier: AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codes\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 0.1, Accuracy: 1.00\n",
      "Test size: 0.2, Accuracy: 1.00\n",
      "Test size: 0.3, Accuracy: 0.93\n",
      "Test size: 0.4, Accuracy: 0.82\n",
      "\n",
      "Preprocessing: standard, Classifier: Gradient Boosting\n",
      "Test size: 0.1, Accuracy: 1.00\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.96\n",
      "Test size: 0.4, Accuracy: 0.90\n",
      "\n",
      "Preprocessing: standard, Classifier: XGBoost\n",
      "Test size: 0.1, Accuracy: 1.00\n",
      "Test size: 0.2, Accuracy: 0.97\n",
      "Test size: 0.3, Accuracy: 0.96\n",
      "Test size: 0.4, Accuracy: 0.93\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer, load_wine, load_digits, load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the datasets\n",
    "datasets = {'breast_cancer': load_breast_cancer(), 'wine': load_wine(), 'digits': load_digits(), 'iris': load_iris()}\n",
    "\n",
    "# Define the best hyperparameters for each classifier\n",
    "adaboost_params = {'n_estimators': 200}\n",
    "gradientboost_params = {'n_estimators': 100, 'max_depth': 5}\n",
    "xgboost_params = {'n_estimators': 50, 'max_depth': 3}\n",
    "\n",
    "# Define different test sizes\n",
    "test_sizes = [0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "# Define data preprocessing methods\n",
    "preprocessing_methods = {'standard': StandardScaler()}\n",
    "\n",
    "# Loop over the datasets\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    X, y = dataset.data, dataset.target\n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    \n",
    "    # Loop over the preprocessing methods\n",
    "    for preprocessing_name, preprocessing_method in preprocessing_methods.items():\n",
    "        # Apply the preprocessing method to the data\n",
    "        X = preprocessing_method.fit_transform(X)\n",
    "\n",
    "        # Loop over the different types of boosting\n",
    "        for clf_name, clf, params in [('AdaBoost', AdaBoostClassifier(), adaboost_params),\n",
    "                                      ('Gradient Boosting', GradientBoostingClassifier(), gradientboost_params),\n",
    "                                      ('XGBoost', XGBClassifier(use_label_encoder=False), xgboost_params)]:\n",
    "            print(f\"Preprocessing: {preprocessing_name}, Classifier: {clf_name}\")\n",
    "            \n",
    "            # Loop over the test sizes\n",
    "            for test_size in test_sizes:\n",
    "                # Split the data into training and testing sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=89)\n",
    "\n",
    "                # Initialize the classifier with the best hyperparameters\n",
    "                clf.set_params(**params, random_state=42)\n",
    "\n",
    "                # Fit the classifier to the training data\n",
    "                clf.fit(X_train, y_train)\n",
    "\n",
    "                # Predict the labels of the test data\n",
    "                y_pred = clf.predict(X_test)\n",
    "\n",
    "                # Calculate the accuracy of the classifier on the test data\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                print(f\"Test size: {test_size}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "            print()\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca703270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
